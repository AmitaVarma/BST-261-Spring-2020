{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGnMtz5kWezG",
        "colab_type": "text"
      },
      "source": [
        "# Lab 1\n",
        "Today's lab consists of practice questions to review the topics presented thus far in class. We will be focusing on:\n",
        "1. Neural network terminology and architecture\n",
        "2. Python\n",
        "3. Forward and backward propagation\n",
        "4. Tensorflow\n",
        "\n",
        "### Question 1\n",
        "Let's review the terminology introduced by thinking about how to design a model for each the following scenarios. It's important to remember that while there is more than one correct answer in these cases, we want to develop an intuition to help save time in parameter tuning, training, computational resources, etc. We'll also briefy touch on some advanced topics to provide a foundation for later in the course, and remember you do not need to use a deep neural network in every case.\n",
        "\n",
        "* *Case 1:* The input is the MNIST handwritten digits dataset (features are 28x28 pixel intensities and labels are digits 0-9). We want to predict which digit the image represents and there are only 10 images per category ($N=100$).\n",
        "  - \n",
        "\n",
        "\n",
        "* *Case 2:* The identical setup but this time there are thousands of images per category.\n",
        "  - \n",
        "\n",
        "\n",
        "* *Case 3:* The identical setup as case 2 but this time images may contain multiple digits or no digits at all.\n",
        "  - \n",
        "\n",
        "\n",
        "* *Case 4:*  The covariates are BMI measurements and reported smoking status, the labels are binary denoting cardiovascular disease. Our sample consists of 70 individuals and we want to predict an individuals' health status based on their BMI and smoking status. We are interested in the effect of BMI on cardiovascular disease.\n",
        "  - \n",
        "\n",
        "\n",
        "* *Case 5:* The input consists of thousands of images of different animals and we want to classify which animal the image contains. \n",
        "  - \n",
        "\n",
        "\n",
        "* *Case 6:* The input consists of thousands of English sentences and we want to predict the next word in the sentences. \n",
        "  - \n",
        "\n",
        "\n",
        "* *Case 7:* The input consists of biomarker status for thousands of loci across thousands of individuals (i.e. Ancestry.com). There are no associated labels and we wish to learn about population substructure.\n",
        "  - "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq7zh9wM8zvg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdKVc4HJXHra",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Draw the architecture of a neural network satisying the following conditions:\n",
        "\n",
        "1. X is a univariate covariate. We will consider the case when X=5.\n",
        "2. There are two hidden layers. The first consists of two nodes, each with a bias term taking values (-1 and 1, respectively). The weight going to the first node takes value 0.5 and the weight going to the second node takes value -0.5.\n",
        "3. The nodes in hidden layer 1 each use a linear activation function.\n",
        "4. Hidden layer 2 consists of a single node with no bias term and the ReLU activation function. The weight from node 1 in hidden layer 1 is 0.3 and the weight from node 2 in hidden layer 1 is 0.7.\n",
        "5. Hidden layer 2 outputs to a single output node. The bias term for the output node is 0.5 and the weight from hidden layer 2 is 2. \n",
        "6. The loss function to be optimized is squared loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqhSrFWpZNWr",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "Implement a single forward pass of the network described in Question 3. You do not need to implement the network in keras and should instead use numpy operations (either scalar or matrix). Start by defining the weights and input matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blT8waJAWbhj",
        "colab_type": "code",
        "outputId": "273470e8-11ad-40eb-bcc4-7482f7bf5812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# Import necessary packages\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "!pip install tensorflow-hub\n",
        "!pip install tfds-nightly\n",
        "import tensorflow_hub as hub\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.18.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (46.0.0)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.6/dist-packages (2.1.0.dev202003190105)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.3.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (4.38.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (19.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.21.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.21.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.18.2)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly) (1.51.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly) (46.0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7qaShKYZbAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMRFFW49Zqea",
        "colab_type": "text"
      },
      "source": [
        "Now perform the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNU-liiGYCjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjccTRMqZxx5",
        "colab_type": "text"
      },
      "source": [
        "And let's print the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBbrhmMxZ00o",
        "colab_type": "code",
        "outputId": "ffd41a81-bf61-4f42-8c4c-e735c29f9198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('The values for the hidden layer 1 are:', hidden1)\n",
        "print('The values for the hidden layer 2 are:', hidden2)\n",
        "print('The post-relu values for the hidden layer 2 are:', hidden2_clamped)\n",
        "print('The value for the output layer is:', y_hat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The values for the hidden layer 1 are: [[ 1.5 -1.5]]\n",
            "The values for the hidden layer 2 are: [[-0.6]]\n",
            "The post-relu values for the hidden layer 2 are: [[0.]]\n",
            "The value for the output layer is: [[0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvci-2MiZ3Vg",
        "colab_type": "text"
      },
      "source": [
        "Calculate the loss for the training example given a label of Y = 0.25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtmec9jLZ8Wi",
        "colab_type": "code",
        "outputId": "e79cf3aa-379f-4d9a-9086-8370487d5585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The loss is: [[0.0625]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ8qWoFFaDpF",
        "colab_type": "text"
      },
      "source": [
        "Implement a single backward pass of the network. Again use numpy. Start by defining the individual gradient terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCP7P1JxaEIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsIdzUbEaNNR",
        "colab_type": "text"
      },
      "source": [
        "We see that a maximum of two quantities are needed for each layer: \n",
        "    \n",
        "1. the partial derivative w.r.t. the input\n",
        "2. the partial derivative w.r.t. the weight/parameter\n",
        "    \n",
        "What is the purpose of each of these quantities?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXp2fvsKaYM5",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "Load the MNIST dataset provided by keras. This contains 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. Split the data into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivbotSmdaZ7J",
        "colab_type": "code",
        "outputId": "f3ed0f02-1db6-4a0e-86b3-3e232fc9a090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load the data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J15SiGP-afKd",
        "colab_type": "text"
      },
      "source": [
        "Print the shape of the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFWovfa1adCV",
        "colab_type": "code",
        "outputId": "b127d45e-25df-46c4-df29-b5a89ff23e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdRKW3hyamxC",
        "colab_type": "text"
      },
      "source": [
        "Let's reshape the data to fit the keras format. Don't worry too much about this chunk for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDNWiWBjanQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
        "    input_shape = (1, 28, 28)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "    input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw1zCV-taq1T",
        "colab_type": "text"
      },
      "source": [
        "Now print the shape again to see what changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMyRa1xEate3",
        "colab_type": "code",
        "outputId": "8af14948-53ec-488d-af52-2f634277f467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5joNuFSawZN",
        "colab_type": "text"
      },
      "source": [
        "Question 2 in Homework 1 asks you to train a neural network on the Boston housing data. This dataset contains features on very different scales (for example there are both binary features and real-valued features). While the MNIST features take on values between 0 and 1 and do not need to be normalized, we will go through the exercise of normalizing the values before training our network.\n",
        "\n",
        "Can you think of other algorithms in which normalization is necessary? Is it necessary in the case of neural networks? Why or why not? \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVRtRWm_azAM",
        "colab_type": "text"
      },
      "source": [
        "Normalize the data. Be sure to normalize the test set with the training set mean and standard deviation. Don't forget to convert the training and testing sets to float32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpAHISANa1lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQGH8zIGa6H1",
        "colab_type": "text"
      },
      "source": [
        "How will the code above need to be changed for Boston housing dataset? Why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO0-5hfca6bH",
        "colab_type": "text"
      },
      "source": [
        "Before we define and fit our model let's one-hot encode the labels. Don't forget to do the same for the testing labels and note you will not need to do this step in the case of regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "920SuVyha80w",
        "colab_type": "code",
        "outputId": "7a0a6473-f8da-4c57-f220-683221c6712e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPGV_eg1a--l",
        "colab_type": "code",
        "outputId": "14b28d4a-fb1f-44a8-b9c6-ed461065911b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl1ydf6GbEFD",
        "colab_type": "text"
      },
      "source": [
        "Now fit a shallow convolutional neural network with a single dense layer. Include 32 convolutional filters of size 3x3 and use the relu activation function.\n",
        "\n",
        "After the convolutional layer, flatted the tensor to be fed into the dense layer.\n",
        "\n",
        "In the dense layer use enough output nodes to have one corresponding to each class label (10). What is the activation function you should use here?\n",
        "\n",
        "In the optimizer use the `Adadelta` optimization function, and choose an appropriate loss function and model performance measure. \n",
        "\n",
        "Run the network for 5 epochs and use a batch_size of 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVT8m0LhbEZa",
        "colab_type": "code",
        "outputId": "4c7571b1-96cc-40bd-b56f-6847c51924b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 361us/sample - loss: 2.1113 - accuracy: 0.3475\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 350us/sample - loss: 1.6393 - accuracy: 0.7203\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 349us/sample - loss: 1.2538 - accuracy: 0.7914\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 342us/sample - loss: 0.9830 - accuracy: 0.8215\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 20s 338us/sample - loss: 0.8059 - accuracy: 0.8405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b92e1d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDPv0OVcbHil",
        "colab_type": "text"
      },
      "source": [
        "Report the test set accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7hTVappbHr8",
        "colab_type": "code",
        "outputId": "caac3bfe-b81c-448f-c187-05bfadde88c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8562\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}